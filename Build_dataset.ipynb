{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The goal of this notebook is to :\n",
    "\n",
    "##### 1. Avoid loading large files into memory.\n",
    "##### 2. Build a train, validation set that ensures balanced classes.\n",
    "#####  3. The size of the validation set  is equal to the size of the test set. \n",
    "#####  4. Avoid loading samples that exist in the test set. \n",
    "####  5. Preprocess the test set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text =  re.sub(r'<.*?>', '', text) # remove anything inside <> html tags\n",
    "    text = re.sub(r'[^\\w\\s]','',text)  # remove all punctuation \n",
    "    text = re.sub(r'[0-9]+', '', text).lower().strip() # remove numbers, strip and lowercase\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lines = []\n",
    "test_labels = []\n",
    "\n",
    "with open(\"europarl.test\") as f:\n",
    "    for line in f:\n",
    "        test_labels.append(line[:2])\n",
    "        test_lines.append(clean(line[2:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({\"text\":test_lines, \"lang\":test_labels})\n",
    "test.columns = [\"lang\", \"text\"]\n",
    "labels = test[\"lang\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bg</td>\n",
       "      <td>европа  не трябва да стартира нов конкурентен ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bg</td>\n",
       "      <td>cs найголямата несправедливост на сегашната об...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bg</td>\n",
       "      <td>de гжо председател гн член на комисията по при...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bg</td>\n",
       "      <td>de гн председател бих искал да започна с комен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bg</td>\n",
       "      <td>de гн председател въпросът за правата на човек...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang                                               text\n",
       "0   bg  европа  не трябва да стартира нов конкурентен ...\n",
       "1   bg  cs найголямата несправедливост на сегашната об...\n",
       "2   bg  de гжо председател гн член на комисията по при...\n",
       "3   bg  de гн председател бих искал да започна с комен...\n",
       "4   bg  de гн председател въпросът за правата на човек..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We notice that the test files contain sentences which have (de), (ce) ... which do not indicate the same language. such as:  (DE) Señor Presidente, considero que esta Directiva marco para la protección del suelo es un grave error que pone en peligro la competitividad de la agricultura europea y el suministro de alimentos en Europa.\n",
    "\n",
    "### Hence we replace them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_symbols = test[\"lang\"].unique() # create the list\n",
    "\n",
    "def replace_lang_symbol(sentence, symbols):\n",
    "    \"\"\"\n",
    "    function to replace \"(de)\" or other language symobols by an empty space\n",
    "    \n",
    "    \"\"\"\n",
    "    for symbol in symbols:\n",
    "        if symbol in sentence: \n",
    "            sentence = sentence.replace(symbol, \"\")\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"text\"] = test[\"text\"].apply(replace_lang_symbol, symbols = lang_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bg</td>\n",
       "      <td>европа  не трябва да стартира нов конкурентен ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bg</td>\n",
       "      <td>найголямата несправедливост на сегашната обща...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bg</td>\n",
       "      <td>гжо председател гн член на комисията по принц...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bg</td>\n",
       "      <td>гн председател бих искал да започна с комента...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bg</td>\n",
       "      <td>гн председател въпросът за правата на човека ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang                                               text\n",
       "0   bg  европа  не трябва да стартира нов конкурентен ...\n",
       "1   bg   найголямата несправедливост на сегашната обща...\n",
       "2   bg   гжо председател гн член на комисията по принц...\n",
       "3   bg   гн председател бих искал да започна с комента...\n",
       "4   bg   гн председател въпросът за правата на човека ..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"test_lang.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bit of  Analytics:  Let's figure out the length of the shortest examples. This will be useful for picking observations for the training and validation set. In fact, detecting the language of a short sentence especially in close languages can be hard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 5 shortest sentences in our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['møt åbn kl',\n",
       " 'r gør emridt',\n",
       " 'herr präsint',\n",
       " 'aäh härra hae',\n",
       " 'vaakem  ümber']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(test[\"text\"]), key = len)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(list(test[\"text\"]), key = len)[0].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shortest sentence in the test set contains three words. Hence we will make sure that the observations in our training and validation set contain at least three words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a validation set that matches the size of the test set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sl    1000\n",
       "pl    1000\n",
       "es    1000\n",
       "it    1000\n",
       "da    1000\n",
       "lt    1000\n",
       "el    1000\n",
       "lv    1000\n",
       "et    1000\n",
       "nl    1000\n",
       "bg    1000\n",
       "ro    1000\n",
       "fr    1000\n",
       "hu    1000\n",
       "sk    1000\n",
       "en    1000\n",
       "sv    1000\n",
       "pt    1000\n",
       "cs    1000\n",
       "fi    1000\n",
       "de    1000\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"lang\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we will create a validation set that has 1000 text per language and a training set that has 4000 text per language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 1000\n",
    "valid_size = test_size \n",
    "train_size = test_size *4\n",
    "data_size = valid_size  + train_size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the training and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following conditions are implemented in order to pick texts samples. They are heuristics that are based on a manual check in order to stay safe and do not reflect a thorough exploration. \n",
    "\n",
    "\n",
    "If a sentence passes the following tests we will \n",
    "    include in the training and validation dataset\n",
    "    \n",
    "    Condition 1: Sentences which language doesn't match the file name are included and start with a parenthesis.\n",
    "    \n",
    "    Condition 2: We want the shortest sentences to have the same length as our test set. In our case 3 words.\n",
    "    \n",
    "    COndition 3,4 ,5: Sentences that end with a point or start with - or the word.\n",
    "                      Report might contain languages that do not match the target language.\n",
    "                      \n",
    "    Condition 6: No overlap betweem test and validation or training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_files = glob(\"raw_data/europarl-v7*\") # Load the language files \n",
    "train_texts = []\n",
    "train_lang = []\n",
    "valid_texts = []\n",
    "valid_lang = []\n",
    "\n",
    "\n",
    "for file in lang_files:\n",
    "    counter = 0\n",
    "    texts = []\n",
    "    languages = []\n",
    "    lang = file[-2:]\n",
    "    with open(file) as f:\n",
    "        if lang not in languages: \n",
    "            for line in f: \n",
    "                    if line[0] != \"(\" and counter < data_size and len(line.split())>2 and line[0] != \"-\" :  # we notice that the files contain non target languages examples put in parenthesis\n",
    "                        \n",
    "                        \n",
    "                        if line[-1]!=\".\" and \"report\" not in line:  \n",
    "                            line = replace_lang_symbol(line, lang_symbols)\n",
    "                            line = clean(line)\n",
    "                            \n",
    "                            if line not in test[\"text\"].values: #last check after applying similar preprocessing\n",
    "                            \n",
    "                                texts.append(clean(line))\n",
    "                                languages.append(lang)\n",
    "                                counter += 1\n",
    "                                \n",
    "            train_texts.extend(texts[:train_size])\n",
    "            train_lang.extend(languages[:train_size])\n",
    "            valid_texts.extend(texts[train_size:])\n",
    "            valid_lang.extend(languages[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame({\"text\": train_texts, \"lang\":train_lang})\n",
    "valid = pd.DataFrame({\"text\": valid_texts, \"lang\":valid_lang})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bg</td>\n",
       "      <td>състав на парламента вж протоколи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bg</td>\n",
       "      <td>одобряване на протокола от предишното заседани...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bg</td>\n",
       "      <td>състав на парламента вж протоколи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bg</td>\n",
       "      <td>проверка на пълномощията вж протоколи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bg</td>\n",
       "      <td>петиции вж протоколи</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang                                               text\n",
       "0   bg                  състав на парламента вж протоколи\n",
       "1   bg  одобряване на протокола от предишното заседани...\n",
       "2   bg                  състав на парламента вж протоколи\n",
       "3   bg              проверка на пълномощията вж протоколи\n",
       "4   bg                               петиции вж протоколи"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train[train[\"lang\"]==\"en\"].index[train_size:], inplace=True) # makes sure we do not oversample from english text\n",
    "valid.drop(valid[valid[\"lang\"]==\"en\"].index[valid_size:], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sl    1000\n",
       "pl    1000\n",
       "es    1000\n",
       "it    1000\n",
       "da    1000\n",
       "lt    1000\n",
       "el    1000\n",
       "lv    1000\n",
       "et    1000\n",
       "nl    1000\n",
       "bg    1000\n",
       "ro    1000\n",
       "fr    1000\n",
       "hu    1000\n",
       "sk    1000\n",
       "en    1000\n",
       "sv    1000\n",
       "pt    1000\n",
       "cs    1000\n",
       "fi    1000\n",
       "de    1000\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid[\"lang\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    4000\n",
       "it    4000\n",
       "el    4000\n",
       "bg    4000\n",
       "pt    4000\n",
       "lv    4000\n",
       "pl    4000\n",
       "sk    4000\n",
       "cs    4000\n",
       "es    4000\n",
       "lt    4000\n",
       "fr    4000\n",
       "nl    4000\n",
       "hu    4000\n",
       "sv    4000\n",
       "fi    4000\n",
       "ro    4000\n",
       "sl    4000\n",
       "da    4000\n",
       "et    4000\n",
       "de    4000\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"lang\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double check if  the training and validation file  contain observations in the test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for t in test[\"text\"]:\n",
    "        if t in train[\"text\"]:\n",
    "            count +=1 \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for t in test[\"text\"]:\n",
    "        if t in valid[\"text\"]:\n",
    "            count +=1 \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can safely generate the training and validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train_lang.csv\", index = False)\n",
    "valid.to_csv(\"valid_lang.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
