{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The goal of this notebook is to :\n",
    "\n",
    "##### 1. Avoid loading large files into memory. \n",
    "##### 2. Build a train, validation set that ensures balanced classes.\n",
    "#####  3. The size of the validation set  is equal to the size of the test set. \n",
    "#####  4. Avoid loading samples that exist in the test set. \n",
    "####  5. Preprocess the test set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text =  re.sub(r'<.*?>', '', text) # remove anything inside <> html tags\n",
    "    text = re.sub(r'[^\\w\\s]','',text)  # remove all punctuation \n",
    "    text = re.sub(r'[0-9]+', '', text).lower().strip() # remove numbers, strip and lowercase\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lines = []\n",
    "test_labels = []\n",
    "\n",
    "with open(\"europarl.test\") as f:\n",
    "    for line in f:\n",
    "        test_labels.append(line[:2])\n",
    "        test_lines.append(clean(line[2:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({\"text\":test_lines, \"lang\":test_labels})\n",
    "test.columns = [\"lang\", \"text\"]\n",
    "labels = test[\"lang\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bg</td>\n",
       "      <td>европа  не трябва да стартира нов конкурентен ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bg</td>\n",
       "      <td>cs найголямата несправедливост на сегашната об...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bg</td>\n",
       "      <td>de гжо председател гн член на комисията по при...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bg</td>\n",
       "      <td>de гн председател бих искал да започна с комен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bg</td>\n",
       "      <td>de гн председател въпросът за правата на човек...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang                                               text\n",
       "0   bg  европа  не трябва да стартира нов конкурентен ...\n",
       "1   bg  cs найголямата несправедливост на сегашната об...\n",
       "2   bg  de гжо председател гн член на комисията по при...\n",
       "3   bg  de гн председател бих искал да започна с комен...\n",
       "4   bg  de гн председател въпросът за правата на човек..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We notice that the test files contain sentences which have (de), (ce) ... which do not indicate the same language. \n",
    "\n",
    "For example:  \n",
    "\n",
    "(DE) Señor Presidente, considero que esta Directiva marco para la protección del suelo es un grave error que pone en peligro la competitividad de la agricultura europea y el suministro de alimentos en Europa.\n",
    "\n",
    "### Hence we replace them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_symbols = test[\"lang\"].unique() # create the list\n",
    "\n",
    "def replace_lang_symbol(sentence, symbols):\n",
    "    \"\"\"\n",
    "    function to replace \"(de)\" or other language symobols by an empty space\n",
    "    \n",
    "    \"\"\"\n",
    "    for symbol in symbols:\n",
    "        if symbol in sentence: \n",
    "            sentence = sentence.replace(symbol, \"\")\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"text\"] = test[\"text\"].apply(replace_lang_symbol, symbols = lang_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20989"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"test_lang.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bit of  Analytics:  Let's figure out the length of the shortest examples. This will be useful for picking observations for the training and validation set. In fact, detecting the language of a short sentence especially in close languages can be hard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 5 shortest sentences in our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['møt åbn kl',\n",
       " 'r gør emridt',\n",
       " 'herr präsint',\n",
       " 'aäh härra hae',\n",
       " 'vaakem  ümber']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(test[\"text\"]), key = len)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(list(test[\"text\"]), key = len)[0].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shortest sentence in the test set contains three words. Hence we will make sure that the observations in our training and validation set contain at least three words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a validation set that matches the size of the test set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lt    1000\n",
       "en    1000\n",
       "nl    1000\n",
       "lv    1000\n",
       "sk    1000\n",
       "bg    1000\n",
       "hu    1000\n",
       "el    1000\n",
       "sl    1000\n",
       "pt    1000\n",
       "pl    1000\n",
       "cs    1000\n",
       "ro     999\n",
       "sv     999\n",
       "fr     999\n",
       "da     999\n",
       "es     999\n",
       "de     999\n",
       "et     999\n",
       "it     998\n",
       "fi     998\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"lang\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we will create a validation set that has 1000 text per language and a training set that has 4000 text per language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 1000\n",
    "valid_size = test_size \n",
    "train_size = test_size *4\n",
    "data_size = valid_size  + train_size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the training and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following conditions are implemented in order to pick texts samples. They are heuristics that are based on a manual check in order to stay safe and do not reflect a thorough exploration. Since we have more than 100,000 texts per languages and will be picking 5000.\n",
    "\n",
    "\n",
    "If a sentence passes the following tests we will \n",
    "    include in the training and validation dataset\n",
    "    \n",
    "#### Condition 1: Some sentences which language don't match the file name are included in \"(\" and start with a parenthesis.\n",
    "    \n",
    "#### Condition 2: We want the shortest sentences to have the same length as our test set. In our case at least 3 words.\n",
    "    \n",
    "#### Conditions 3,4 ,5: Some sentences that end with a point or start with \"-\" or the word \"report\" contain  languages that do not match the target language. \n",
    "                      \n",
    "#### Conditions 6: No overlap betweem test and validation or training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_files = glob(\"raw_data/europarl-v7*\") # Load the language files \n",
    "train_texts = []\n",
    "train_lang = []\n",
    "valid_texts = []\n",
    "valid_lang = []\n",
    "\n",
    "\n",
    "for file in lang_files:\n",
    "    counter = 0\n",
    "    texts = []\n",
    "    languages = []\n",
    "    lang = file[-2:]\n",
    "    with open(file) as f:\n",
    "        if lang not in languages: \n",
    "            for line in f: \n",
    "                    if line[0] != \"(\" and counter < data_size and len(line.split())>2 and line[0] != \"-\" :  \n",
    "                        \n",
    "                        \n",
    "                        if line[-1]!=\".\" and \"report\" not in line:  \n",
    "                            line = replace_lang_symbol(line, lang_symbols)\n",
    "                            line = clean(line)\n",
    "                            \n",
    "                            if line not in test[\"text\"].values and line not in texts : #last checks after applying similar preprocessing\n",
    "                            \n",
    "                                texts.append(clean(line))\n",
    "                                languages.append(lang)\n",
    "                                counter += 1\n",
    "                                \n",
    "            train_texts.extend(texts[:train_size])\n",
    "            train_lang.extend(languages[:train_size])\n",
    "            \n",
    "            valid_texts.extend(texts[train_size:])\n",
    "            valid_lang.extend(languages[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame({\"text\": train_texts, \"lang\":train_lang})\n",
    "valid = pd.DataFrame({\"text\": valid_texts, \"lang\":valid_lang})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bg</td>\n",
       "      <td>състав на парламента вж протоколи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bg</td>\n",
       "      <td>одобряване на протокола от предишното заседани...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bg</td>\n",
       "      <td>проверка на пълномощията вж протоколи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bg</td>\n",
       "      <td>петиции вж протоколи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bg</td>\n",
       "      <td>предаване на текстове на споразумения от съвет...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang                                               text\n",
       "0   bg                  състав на парламента вж протоколи\n",
       "1   bg  одобряване на протокола от предишното заседани...\n",
       "2   bg              проверка на пълномощията вж протоколи\n",
       "3   bg                               петиции вж протоколи\n",
       "4   bg  предаване на текстове на споразумения от съвет..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train[train[\"lang\"]==\"en\"].index[train_size:], inplace=True) # makes sure we do not oversample from english text\n",
    "valid.drop(valid[valid[\"lang\"]==\"en\"].index[valid_size:], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lt    1000\n",
       "it    1000\n",
       "nl    1000\n",
       "lv    1000\n",
       "sk    1000\n",
       "bg    1000\n",
       "fi    1000\n",
       "de    1000\n",
       "es    1000\n",
       "da    1000\n",
       "el    1000\n",
       "fr    1000\n",
       "hu    1000\n",
       "en    1000\n",
       "ro    1000\n",
       "sv    1000\n",
       "sl    1000\n",
       "pt    1000\n",
       "et    1000\n",
       "pl    1000\n",
       "cs    1000\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid[\"lang\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lt    4000\n",
       "pt    4000\n",
       "es    4000\n",
       "it    4000\n",
       "en    4000\n",
       "sl    4000\n",
       "lv    4000\n",
       "sk    4000\n",
       "bg    4000\n",
       "sv    4000\n",
       "et    4000\n",
       "hu    4000\n",
       "pl    4000\n",
       "fr    4000\n",
       "nl    4000\n",
       "de    4000\n",
       "da    4000\n",
       "el    4000\n",
       "ro    4000\n",
       "fi    4000\n",
       "cs    4000\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"lang\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double check if  the training and validation file  contain observations in the test file:\n",
    "Step 1: Concatenate all files.\n",
    "\n",
    "Step 2: Check length\n",
    "\n",
    "Step 3: Drop duplicates\n",
    "\n",
    "Step 4: If the same length as in step 2 appears, then we don't have common duplicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat([train,valid,test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125989"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125989"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d) #we have the same length, henve no duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can safely generate the training and validation set after shuffling the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sample(frac = 1.0)\n",
    "valid = valid.sample(frac = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train_lang.csv\", index = False)\n",
    "valid.to_csv(\"valid_lang.csv\", index = False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
